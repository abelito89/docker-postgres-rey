# fastapi + PostgreSQL + Docker

En este proyecto se ha creado un CRUD utilizando FastAPI como backend, PostgreSQL como gestor de base de datos y Docker para ejecutar todo el entorno.

## Conectando m√∫ltiples servicios en Docker
Cuando desarrollamos alguna soluci√≥n en Docker, una alternativa ser√≠a ejecutar los contenedores de manera independiente pero no es la m√°s c√≥moda (opini√≥n del que escribe este README üòä)

Si fu√©ramos a hacerlo de esta forma deber√≠amos seguir estos pasos.

1. Ejecutar el comando para correr el contenedor de PostgreSQL
```
docker run -d --name db \
  -e POSTGRES_USER=miusuario \
  -e POSTGRES_PASSWORD=mipassword \
  -e POSTGRES_DB=mibasededatos \
  postgres:latest
```
* Esto crear√° un contendeor de PostgreSQL, llamado `db` con un usuario llamado `miusuario`, password `mipassword` y una base de datos llamada `mibasededatos`

2. Despu√©s de que el contenedor de PostgreSQL est√© listo (pudiera tardar unos minutos), necesitamos saber la direcci√≥n IP que se le ha asigando al mismo ejecutando el siguiente comando
```
postgres_ip=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' db)

```
* Este comando almacena la direcci√≥n IP en la variable `postgres_ip`

* En este comando, al final se le especifica el nombre del contenedor (`db` en este caso) del cual se desea saber la direcci√≥n IP. Tenga en cuenta, que Docker gestiona la red de una manera particular y m√°gica y no siempre tenemos que entenderlo (opini√≥n del que escribe üòä)

3. Por √∫ltimo, debemos ejecutar el comando para crear el contenedor de fastapi y conectarlo al contenedor de PostgreSQL
```
docker run -d --name app \
  -e POSTGRES_HOST=$postgres_ip \
  -e POSTGRES_PORT=5432 \
  -e POSTGRES_USER=miusuario \
  -e POSTGRES_PASSWORD=mipassword \
  -e POSTGRES_DB=mibasededatos \
  -p 80:80 \
  app:latest
```
* En este comando hay algunas cosas perdidas, pero que no describiremos ya que esta secci√≥n es solo para dar una idea de lo que se pudiera hacer. Siga leyendo, y si ha venido probando algo hasta este punto y no ha funcionado culpe a ChatGPT porque el que escribe esto jam√°s ha hecho ninguno de estos pasos üöÄ üòé

## Conectando varios servicios usando docker-compose
La manera que aconsejable ser√≠a usando docker-compose. Seg√∫n la explicaci√≥n de ChatGPT y su interesante analog√≠a:

Docker Compose es como un "maestro de ceremonias" para aplicaciones que se ejecutan en contenedores. Imagina que est√°s organizando una fiesta y necesitas varios elementos: m√∫sica, luces, comida, etc. Con Docker Compose, puedes describir todos estos elementos en un solo "men√∫" (archivo YAML) y luego decirle a Docker que siga ese men√∫ para configurar y ejecutar todos los servicios necesarios autom√°ticamente. Simplifica la gesti√≥n de aplicaciones, permitiendo a las personas que no conocen Docker f√°cilmente tener una fiesta (o aplicaci√≥n) funcionando sin lidiar con detalles t√©cnicos complicados.

Basado en esto, necesitamos crear un fichero donde se describa nuestra aplicaci√≥n. No olvidar nunca, que nuestra aplicaci√≥n tiene que entenderse como el conjunto de dos contenedores conectados entre s√≠. No podemos desligarlos y decir que la App es solo fastapi, o solo PostgreSQL.

### Creando el fichero docker-compose
Ahora puede seguir estos pasos, y si algo no funciona, entonces S√ç culpe al que escribi√≥ esta documentaci√≥n üòÖ

En la ruta principal de tu projecto, crea un fichero llamado `docker-compose.yml` con la siguiente estructura
```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 8000:8000
    volumes:
      - .:/Proyecto_docker1
    depends_on:
      - db

  db:
    image: postgres:latest
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:

```

Vamos a explicar paso a paso lo que cada una de estas l√≠neas significa

`version: '3.8'`
* Es la versi√≥n de docker-compose se que est√° usando. Considere que docker-compose es una herramienta asociada a Docker, y como tal tiene varias versiones. Usar la versi√≥n 3.8 deber√≠a ser suficiente. La versi√≥n de docker-compose esta asociada tambi√©n al engine de Docker que se utilice. Tenga esto en cuanta, en caso de que el engine de Docker que tiene instalado no soporte la versi√≥n especificada en el docker-compose. M√°s informaci√≥n aqu√≠: [Docker compose verioning](https://docs.docker.com/compose/compose-file/compose-versioning/)

`services`
* B√°sicamente esta l√≠nea indica que a continuaci√≥n se describir√°n los servicios contenidos en el docker-compose. Importante notar que las pr√≥ximas l√≠neas todas tienen un nivel de indentaci√≥n m√°s a la derecha; o sea, est√°n contenidas en la secci√≥n services

```yaml
app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 8000:8000
    volumes:
      - .:/Proyecto_docker1
    depends_on:
      - db
```
* Este es el primer contendor, el de la App web, el de fastAPI.

* Tiene internamente 4 secciones: `build`, `ports`, `volumes` y `depends_on`
    * La secci√≥n `build` especifica ¬øc√≥mo se construir√° este contenedor? En este caso le estamos diciendo que use como `context` . (es decir la ruta donde esta almacenado el docker-file) y que el `dockerfile` a usar es Dockerfile. Esto buscar√° en la ruta principal del proyecto un fichero Dockerfile y construir√° la imagen a partir de lo que haya en ese fichero.
    
    * La secci√≥n `ports` indica los puertos que se van a exponer en nuestro contenedor, y est√° escrito siguiendo el patr√≥n <puerto_en_navegador_local>:<puerto_del_contenedor>. Lo que se est√° diciendo aqu√≠ es "cuando el usuario escriba la URL xxxxxx:8000" con√©ctate al puerto 8000 dentro de este contenedor. No especifico nada en la URL porque lo que importa en este punto es a que puerto nos estamos conectando.
    
    * La secci√≥n `volumes` se usa para 'conectar' carpetas locales (en la PC donde estamos trabajando) con carpetas dentro del contenedor. Entienda que estar√° escribiendo c√≥digo en su PC, y queremos que ese c√≥digo (carpetas, ficheros, etc) est√©n copiados dentro del contenedor. B√°sicamente estamos diciendo aqu√≠: todo lo que esta en esta carpeta (gracias al `.:`) copialo para dentro del contenedor, en la ruta `/Proyecto_docker1`. Este √∫ltimo nombre no es arbitrario, y est√° relacionado con lo que se escribi√≥ en el Dockerfile; pues en ese fichero se cre√≥ esa carpeta. Revise el Dockerfile si desea entender mejor.

    * La secci√≥n `depends_on` es la que realiza la 'magia' de conectar ambos contenedores. Se le est√° diciendo que el contenedor `app` depender√° del contenedor `db`

* La pr√≥xima secci√≥n dentro de `services` es la que describe al contenedor de PostgreSQL y este es m√°s simple

```yaml
db:
    image: postgres:latest
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
```
* Tiene 4 secciones: `image`, `environment`, `volumes` y `ports`
    * `image` especifica qu√© imagen se est√° usando. En este caso, como podemos usar la imagen oficial de postgres sin ninguna modificaci√≥n podemos escribir directamente `image: postgres:latest`; a diferencia del contenedor anterior que teniamos que construir la imagen a partir de un Docker file. Es decir, tenga en cuenta que tenemos dos opciones: image: <image_name> si podemos usar una imagen previamente creada y que no tenemos que modificar o build (con su context y su Dockerfile) si necesitamos construir la imagen a partir de un Dockerfile

    * `environment` especifica las variable de entorno que se usar√°n en este contenedor. Para PostgreSQL necesitamos especificar al menos `POSTGRES_USER`, `POSTGRES_PASSWORD` y `POSTGRES_DB`. Luego, en nuestra app de fastapi podremos referirnos a ellas mediante esos nombre (m√°s detalles luego). IMPORTANTE: NO es buena pr√°ctica, y NO es aconsejable almacenar los valores en texto plano aqu√≠ en el docker-compose, ya que este fichero se va a incluir en un repositorio, y estar√≠amos exponiendo las credenciales de nuestra aplicaci√≥n. Por eso, La soluci√≥n ser√≠a crear un fichero `.env`, el cual se incluye dentro del fichero `.gitignore` y nunca se har√≠a commit del mismo, de ese modo esas credenciales no se comparten. Entonces aqui nos referimos no a los valores sino a los nombres de las variables en el fichero .env (este fichero lo crearemos m√°s adelante)

    * `volumes` similar al anterior servicio, solo que esta vez al crear volumenes para PostgreSQL es de esta forma, y esta relacionado con la √∫ltima l√≠nea del docker-compose. Honestamente nunca me he dedicado a intentar cambiarlo üòä

* La √∫ltima secci√≥n del docker-compose es la siguiente, y no es m√°s que la definic√≥n volumenes generales (no hay mucho que decir aqui), y esta relacionado con la forma en la que describimos el volumen de `db`. Importante respetar la indentaci√≥n (esta secci√≥n est√° al mismo nivel que `services`)
```yaml
volumes:
  postgres_data:
```

## Ejecutando los servicios descritos en el docker-compose

Ahora toca el turno de ejecutar nuestra App (de nuevo, ver la App como la interconexi√≥n de dos contenedores corriendo al mismo tiempo)

Primero, estemos seguros de lo siguiente (para que si algo est√° roto no me culpen a m√≠ üòä)

* docker compose est√° instalado en nuestra PC: esto es muy importante, y tal vez debio mencionarse desde el inicio. Estemos seguros de que docker compose est√° instalado. Si estan usando algun cliente como Docker Desktop deberia estar instalado. Pudiera comprobarlo usando el comando `docker-compose --version`

* Tenemos un fichero Dockerfile en la misma ruta en la que se encuentra el fichero docker-compose.yml con el siguiente contenido.

```dockerfile
# Usa la imagen base de Python 3.11
FROM python:3.11

# Establece el directorio de trabajo en /Proyecto_docker1
WORKDIR /Proyecto_docker1

# Copia el archivo de requisitos al contenedor
COPY requirements.txt /Proyecto_docker1

# Instala las dependencias desde el archivo requirements.txt
RUN pip install --no-cache-dir -r /Proyecto_docker1/requirements.txt

# Copia el c√≥digo fuente de tu aplicaci√≥n al contenedor
COPY . .

# Expone el puerto 8000 para FastAPI
EXPOSE 8000

# Comando por defecto para ejecutar la aplicaci√≥n cuando el contenedor se inicie
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

* Tenemos un fichero `requirements.txt` en la misma ruta donde se encuentra el docker-compose.yml con el siguiente contenido
```
fastapi
uvicorn
sqlalchemy
pandas
starlette
itsdangerous
jinja2
psycopg2
python-dotenv
```

* Tenemos el fichero `.env` en la misma ruta del docker-compose.yml con el siguiente contenido. Los valores 'miusuario', 'mipassword' y 'mibasededatos' son las credenciales que necesitar√≠as si te deseas conectar a tu base de datos desde otro cliente como PGAdmin, o alguna extensi√≥n de VSCode que te permite conectarte a bases de datos. 
```
POSTGRES_USER=miusuario
POSTGRES_PASSWORD=mipassword
POSTGRES_DB=mibasededatos
```

* Tenemos el fichero `main.py` en la misma ruta donde se encuentra el fichero docker-compose.yml con el siguiente contenido (este por ahora, ya luego le agregaremos mas detalles para la conexi√≥n con la base de datos)

```python
from fastapi import FastAPI

app = FastAPI()
@app.get('/')
def home():
    return {"message":"Hello World"}
```

Ahora ejecutemos el comando 
```
docker compose up
```
En este punto se construir√° la imagen `app` con los datos especificados en el fichero Dockerfile, y se descargar√° la imagen de postgres para construir el contenedor `db`. Esto puede tardar un poco dependiendo de su conexi√≥n a Internet

Cuando vean en consola este resultado entonces deber√° ser capaz de ver su aplicaci√≥n de fastapi corriendo en http://localhost:8000 y ahora s√≠ culparme si no funciona üòä

```
e=0.001 s; distance=0 kB, estimate=0 kB; lsn=0/1954560, redo lsn=0/1954560
db-1   | 2024-03-02 05:58:41.573 UTC [1] LOG:  database system is ready to accept connections
app-1  | INFO:     Started server process [1]
app-1  | INFO:     Waiting for application startup.
app-1  | INFO:     Application startup complete.
app-1  | INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

## Comprobar que ambos contenedores est√°n corriendo

La manera m√°s r√°pida ser√≠a ejecutar el comando `docker ps` y deber√≠a ver algo como esto
| CONTAINER ID  | IMAGE                     | COMMAND                   | CREATED          | STATUS         | PORTS                      | NAMES                       |
|---------------|---------------------------|---------------------------|------------------|----------------|----------------------------|-----------------------------|
| b648b20500b1  | docker-postgres-rey-app  | "uvicorn main:app --‚Ä¶"   | 3 minutes ago    | Up 3 minutes   | 0.0.0.0:8000->8000/tcp     | docker-postgres-rey-app-1   |
| e5a5d4ba36d6  | postgres:latest           | "docker-entrypoint.s‚Ä¶"   | 54 minutes ago   | Up 3 minutes   | 5432/tcp                   | docker-postgres-rey-db-1    |

En este resultado se puede ver que tenemos dos contenedores corriendo, la imagen que usa cada uno, el comando que esta ejecutando, cuando se crearon y el estado

## Detener/Iniciar ambos contenedores

Si ambos contenedores est√°n corriendo, su consola habr√° quedado 'atrapada' y lo que debe hacer para detenerlos es `Ctrl + C`. Luego, si desea iniciarlos de nuevo pues vuelve a ejecutar `docker compose up`

## docker compose up vs docker-compose up

Para ejecutar los contenedores es posible usar tambi√©n `docker-compose up` con un gui√≥n separando ambas palabras. Esta era la manera antigua de hacerlo, la verdad no tengo mucho que decir aqu√≠.


## Agregar l√≥gica de Postgress en nuestra app fastapi
Vamos a modificar nuestro c√≥digo de la siguiente forma para establecer una conexi√≥n con el contenedor de PostgreSQL, crear una tabla `usuario` y crear varios endpoints para hacer un CRUD de usuarios.

```python
import os
import logging
from dotenv import load_dotenv

from fastapi import FastAPI
from sqlalchemy import create_engine, Column, Integer, String, MetaData
from sqlalchemy.orm import declarative_base, sessionmaker

# Usando logging para mostrar mensajes en la consola.
# Todos amamos print('XXXXX') pero logging es la manera correcta/profesional
# de hacerlo :)
logging.basicConfig(level=logging.INFO)
_logger = logging.getLogger(__name__)

# Leyendo las variables de entorno desde el archivo el environment,
# lo cual es aconsejable para no exponer informaci√≥n sensible.
load_dotenv()
POSTGRES_USER = os.getenv("POSTGRES_USER")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD")
POSTGRES_DB = os.getenv("POSTGRES_DB")

# logueando las variables de entorno para estar seguros de que
# se leyeron correctamente. No haga esto en producci√≥n,
# es solo una medida para estar seguros de que tenemos los datos
# necesarios para conectarnos a la base de datos.
_logger.info(f"... POSTGRES_USER: {POSTGRES_USER}")
_logger.info(f"... POSTGRES_PASSWORD: {POSTGRES_PASSWORD}")
_logger.info(f"... POSTGRES_DB: {POSTGRES_DB}")

DATABASE_URL = f"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@db:5432/{POSTGRES_DB}"

_logger.info(f"... DATABASE_URL: {DATABASE_URL}")

# Creando la conexi√≥n a la base de datos
engine = create_engine(DATABASE_URL)

# Definici√≥n de la tabla 'usuario'.
metadata = MetaData()
Base = declarative_base()

class Usuario(Base):
    __tablename__ = "usuario"
    id = Column(Integer, primary_key=True, index=True)
    nombre = Column(String, index=True)
    apellido = Column(String, index=True)
    email = Column(String, index=True)

Base.metadata.create_all(bind=engine)

# Configuraci√≥n de la sesi√≥n de la base de datos
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Configuraci√≥n de la aplicaci√≥n FastAPI
app = FastAPI()

# Endpoint para agregar usuario
@app.post("/agregar-usuario/")
async def agregar_usuario(nombre: str, apellido: str, email: str):
    db = SessionLocal()
    usuario = Usuario(nombre=nombre, apellido=apellido, email=email)
    db.add(usuario)
    db.commit()
    db.refresh(usuario)
    db.close()
    return {"message": "Usuario agregado correctamente"}

# Endpoint para obtener todos los usuarios
@app.get("/usuarios/")
async def obtener_usuarios():
    db = SessionLocal()
    usuarios = db.query(Usuario).all()
    db.close()
    return usuarios

# Endponit para obtener un usuario por su email
@app.get("/usuario/{email}")
async def obtener_usuario(email: str):
    db = SessionLocal()
    usuario = db.query(Usuario).filter(Usuario.email == email).first()
    db.close()
    return usuario

# Endpoint para eliminar un usuario por su email
@app.delete("/usuario/{email}")
async def eliminar_usuario(email: str):
    db = SessionLocal()
    usuario = db.query(Usuario).filter(Usuario.email == email).first()
    db.delete(usuario)
    db.commit()
    db.close()
    return {"message": "Usuario eliminado correctamente"}

# Endpoint para actualizar un usuario por su email
@app.put("/usuario/{email}")
async def actualizar_usuario(email: str, nombre: str, apellido: str):
    db = SessionLocal()
    usuario = db.query(Usuario).filter(Usuario.email == email).first()
    usuario.nombre = nombre
    usuario.apellido = apellido
    db.commit()
    db.close()
    return {"message": "Usuario actualizado correctamente"}
```

## Probando nuestra App
Al acceder a http://localhost:800/docs podr√° probar cada uno de los endpoints definidos y crear/editar/listar/eliminar usuarios. 

## Una sugerencia final
En mi caso particular, he encontrado un plugin de VSCode que me encanta, pues puedo conectarme a mi Base de Datos desde el mismo VSCode y comprobar que mis datos se estan guardando correctamente sin tener que instalar nada extra. 

* Instala el pluggin MySQL

![Image](doc/mysql_vscode_plugin.png)

* Configura una nueva conexi√≥n

![Image](doc/new_connection.png)

* Selecciona PostgreSQL en las pesta√±as de bases de datos soportadas y agrega los datos de tu conexi√≥n
  * Name: cualquier nombre que quieras para esta conexi√≥n
  * Host: localhost
  * Username / Password / Database: Usa los mismos valores que agregaste en el fichero `.env`

![Image](doc/connection_setup.png)

* Comprueba los datos en tu BD
  * Fijate en el espacio donde pone SLECT * FROM usuario LIMIT 100. Ah√≠ puedes ejecutar SQL queries para leer tus datos, o puedes seleccionar celdas y eliminarlas, etc. 

![Image](doc/data.png)




